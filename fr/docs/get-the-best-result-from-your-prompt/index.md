# Obtenez le meilleur résultat pour votre prompt

## Nul ne sait quelle IA répondra le mieux à votre prompt avant de les comparer

Les classements actuels des performances des LLM, tels que ceux disponibles sur [lmsys.org](http://lmsys.org) ou [livebench.ai](http://livebench.ai), estiment la probabilité qu'un modèle surpasse un autre dans des catégories spécifiques. Notamment, le LLM le mieux classé n'a qu'une probabilité légèrement supérieure à 50 % de surpasser celui classé en deuxième position.

Même avec des algorithmes sophistiqués qui prennent en compte les classements spécifiques à des catégories (par exemple, raisonnement, codage, rédaction, langues, etc.), la différence de performance n'est pas significative.

Par conséquent, la meilleure approche consiste à reprompter et à comparer les modèles :

- Reprompter avec un deuxième modèle.
- Disposer de plusieurs propositions d'IA permet de sélectionner le meilleur résultat.

## Données empiriques issues de Mammouth

### **Données de reprompting issues de Mammouth AI**

| **Nombre de modèles de texte sollicités par prompt** | **% du total des prompts** |
| ---------------------------------------------------- | -------------------------- |
| >= 4                                                 | 7 %                        |
| >= 3                                                 | 12 %                       |
| >= 2                                                 | 34 %                       |
| = 1                                                  | 66 %                       |

| **Nombre de modèles d'image sollicités par prompt** | **% du total des prompts** |
| --------------------------------------------------- | -------------------------- |
| >= 3                                                | 19 %                       |
| >= 2                                                | 41 %                       |
| = 1                                                 | 59 %                       |

### Pour 66 % des requêtes textuelles quotidiennes, les utilisateurs sollicitent un seul modèle

- 66 % des requêtes des utilisateurs ne nécessitent pas de reprompting (d'après les données de [Mammouth.ai](http://Mammouth.ai)).

### Pour 34 % des requêtes textuelles quotidiennes, les utilisateurs sollicitent plus d'un modèle

- Par conséquent, 34 % du total des requêtes bénéficient d'un reprompting. Ces 34 % correspondent aux requêtes de haute valeur. Ces requêtes sont plus créatives et plus complexes.
  - 24 % du total des prompts sont repromptés avec exactement 1 modèle.
  - 12 % du total des prompts sont repromptés avec 2 modèles ou plus.
  - 7 % du total des prompts sont repromptés avec plus de 3 modèles.

## Le reprompting est encore plus populaire avec les outils de génération d'images

- En effet, 41 % des requêtes d'images sont repromptées avec au moins un modèle.
- 19 % de ces requêtes sont repromptées avec plus de deux modèles.

## À mesure que les modèles d'IA deviennent plus performants, la définition du meilleur résultat devient plus subjective et moins objective

Il existe deux raisons de préférer le résultat d'un modèle à un autre :

- **La raison objective** : L'utilisateur privilégiera le modèle qui respecte les règles de son prompt et fournit la réponse correcte.
- **La raison subjective** : Lorsque deux IAs fournissent une réponse objectivement correcte, un modèle reste préféré par l'utilisateur pour des raisons subjectives.

→ À mesure que les performances des IA s'améliorent, la différenciation passe progressivement de l'objectif au subjectif. Cela rend le reprompting encore plus pertinent. D'où cet [Indice de popularité des LLM](../introducing-llm-popularity-index/).